{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "practiceDataFactory10"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/SCD2EmpSqlTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "PracticeSqlDatabaseConnection",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "RealTime Datasets"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "SurrKey",
						"type": "int",
						"precision": 10
					},
					{
						"name": "emp_id",
						"type": "int",
						"precision": 10
					},
					{
						"name": "empName",
						"type": "varchar"
					},
					{
						"name": "gender",
						"type": "varchar"
					},
					{
						"name": "country",
						"type": "varchar"
					},
					{
						"name": "is_active",
						"type": "bit"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "SCD2Employee"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/employesSqlTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "PracticeSqlDatabaseConnection",
					"type": "LinkedServiceReference"
				},
				"folder": {
					"name": "Practice"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "empid",
						"type": "varchar"
					},
					{
						"name": "empname",
						"type": "varchar"
					},
					{
						"name": "Gender",
						"type": "varchar"
					},
					{
						"name": "Country",
						"type": "varchar"
					},
					{
						"name": "Salary",
						"type": "varchar"
					},
					{
						"name": "DeptID",
						"type": "varchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "employees"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow10_pivot_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "pivotOnDeptwiseGenderEmployeeCount"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"empData pivot(groupBy(DeptID),",
						"     pivotBy(Gender),",
						"     Total = count(empid),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivotOnDeptwiseGenderEmployeeCount",
						"pivotOnDeptwiseGenderEmployeeCount sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['pivotDataGenderwiseEmpcount.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow11_unpivot_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "vendorData",
								"type": "DatasetReference"
							},
							"name": "vendorData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "unpivotOnVendorFruitsColumn"
						}
					],
					"scriptLines": [
						"source(output(",
						"          PO as string,",
						"          Vender as string,",
						"          Apple as string,",
						"          Mango as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> vendorData",
						"vendorData unpivot(output(",
						"          Fruits as string,",
						"          Count as string",
						"     ),",
						"     ungroupBy(PO,",
						"          Vender),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivotOnVendorFruitsColumn",
						"unpivotOnVendorFruitsColumn sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['unpivot.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow12_surrogate_key')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"empData keyGenerate(output(surrogate_key as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          surrogate_key,",
						"          empid,",
						"          empname,",
						"          Gender,",
						"          Country,",
						"          Salary,",
						"          DeptID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['surrogatekey.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          surrogate_key,",
						"          empname,",
						"          Gender,",
						"          Country,",
						"          Salary,",
						"          DeptID",
						"     ),",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow13_window_opeartion')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "windowOnDepartmenttoCalcSalary"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"empData window(over(DeptID),",
						"     desc(Salary, true),",
						"     avgSalary = avg(toInteger(Salary)),",
						"          denseRank = denseRank()) ~> windowOnDepartmenttoCalcSalary",
						"windowOnDepartmenttoCalcSalary sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['windowOpeartion.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname,",
						"          Gender,",
						"          Country,",
						"          Salary,",
						"          DeptID,",
						"          avgSalary,",
						"          denseRank",
						"     ),",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15_parameterize_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "filterDynamically"
						}
					],
					"scriptLines": [
						"parameters{",
						"     gender as string",
						"}",
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"empData filter(Gender ==$gender) ~> filterDynamically",
						"filterDynamically sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ParameterizeDataflow.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow17_fixed_lengthOpeartion')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time scenarios"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "fixedlenghtData",
								"type": "DatasetReference"
							},
							"name": "fixedLengthData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "derivedColumnFromFixedScema"
						},
						{
							"name": "selectreqCol"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Column_1 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> fixedLengthData",
						"fixedLengthData derive(empID = substring(Column_1, 1, 4),",
						"          Name = substring(Column_1, 5, 10),",
						"          State = substring(Column_1, 15, 2),",
						"          phoneNumber = substring(Column_1, 17, 10)) ~> derivedColumnFromFixedScema",
						"derivedColumnFromFixedScema select(mapColumn(",
						"          empID,",
						"          Name,",
						"          State,",
						"          phoneNumber",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectreqCol",
						"selectreqCol sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['fixedLengthData.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow18_deleteDuplicate_rows')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time scenarios"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "oldEMpData"
						},
						{
							"dataset": {
								"referenceName": "newEmpData",
								"type": "DatasetReference"
							},
							"name": "NewEmpData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "union1"
						},
						{
							"name": "aggregateToProcessIncrementalRows"
						},
						{
							"name": "sortInAsendingOrder"
						},
						{
							"name": "derivedColumnConvertStringToInteger"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> oldEMpData",
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> NewEmpData",
						"oldEMpData, NewEmpData union(byName: true)~> union1",
						"union1 aggregate(groupBy(empid),",
						"     each(match(name!='empid'), $$ = first($$))) ~> aggregateToProcessIncrementalRows",
						"derivedColumnConvertStringToInteger sort(asc(empid, true)) ~> sortInAsendingOrder",
						"aggregateToProcessIncrementalRows derive(empid = toInteger(empid)) ~> derivedColumnConvertStringToInteger",
						"sortInAsendingOrder sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['incrementalEmpData.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow19_incremental_key_from_existing_source')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time scenarios"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "old_empDataFromWhichIncrementKeysStart",
								"type": "DatasetReference"
							},
							"name": "oldEmpData"
						},
						{
							"dataset": {
								"referenceName": "Increment_existing_key_data",
								"type": "DatasetReference"
							},
							"name": "newDatasetWithoutEmpid"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputIncremenetedData",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "derivedColumnDummyToGetMaxvalueOfID"
						},
						{
							"name": "aggregateMaxEmpId"
						},
						{
							"name": "joinDummyMaxStreamtonewEMPdata"
						},
						{
							"name": "surrogateKeyAddempId"
						},
						{
							"name": "derivedColumnIncrementedEmpIdColumn"
						},
						{
							"name": "selectRequiredColumns"
						},
						{
							"name": "unionOfOlddataWithIncrementedData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> oldEmpData",
						"source(output(",
						"          empname as string,",
						"          Gender as string,",
						"          Country as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> newDatasetWithoutEmpid",
						"oldEmpData derive(dummy = 'dummy') ~> derivedColumnDummyToGetMaxvalueOfID",
						"derivedColumnDummyToGetMaxvalueOfID aggregate(groupBy(dummy),",
						"     MaxID = toString(max(toInteger(empid)))) ~> aggregateMaxEmpId",
						"aggregateMaxEmpId, newDatasetWithoutEmpid join(1==1,",
						"     joinType:'cross',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinDummyMaxStreamtonewEMPdata",
						"joinDummyMaxStreamtonewEMPdata keyGenerate(output(empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKeyAddempId",
						"surrogateKeyAddempId derive(empid = toString( (toInteger(MaxID) + toInteger(empid)))) ~> derivedColumnIncrementedEmpIdColumn",
						"derivedColumnIncrementedEmpIdColumn select(mapColumn(",
						"          empid,",
						"          empname,",
						"          Gender,",
						"          Country,",
						"          Salary,",
						"          DeptID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectRequiredColumns",
						"oldEmpData, selectRequiredColumns union(byName: true)~> unionOfOlddataWithIncrementedData",
						"unionOfOlddataWithIncrementedData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     partitionFileNames:['incrementalEmpData.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1_Join_Operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						},
						{
							"dataset": {
								"referenceName": "deptData",
								"type": "DatasetReference"
							},
							"name": "deptData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "destinationData"
						}
					],
					"transformations": [
						{
							"name": "joinBothDatasets"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"source(output(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> deptData",
						"empData, deptData join(empData@DeptID == deptData@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinBothDatasets",
						"joinBothDatasets sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname,",
						"          Salary,",
						"          DeptName",
						"     )) ~> destinationData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow20_log_pipelinedata_using_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time scenarios"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "dummyData",
								"type": "DatasetReference"
							},
							"name": "duumyData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "logsData",
								"type": "DatasetReference"
							},
							"name": "logOutputData"
						}
					],
					"transformations": [
						{
							"name": "derivedColumnTologPipelinelogs"
						},
						{
							"name": "selectReqColumns"
						}
					],
					"scriptLines": [
						"parameters{",
						"     adfName as string,",
						"     pipelineName as string,",
						"     triggerName as string,",
						"     runId as string,",
						"     triggerTime as string,",
						"     status as string,",
						"     fileName as string",
						"}",
						"source(output(",
						"          Column_1 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> duumyData",
						"duumyData derive(adfName = $adfName,",
						"          pipelineName = $pipelineName,",
						"          triggerName = $triggerName,",
						"          runId = $runId,",
						"          triggerTime = $triggerTime,",
						"          status = $status,",
						"          fileName = $fileName) ~> derivedColumnTologPipelinelogs",
						"derivedColumnTologPipelinelogs select(mapColumn(",
						"          adfName,",
						"          pipelineName,",
						"          triggerName,",
						"          runId,",
						"          triggerTime,",
						"          status,",
						"          fileName",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectReqColumns",
						"selectReqColumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          saleDate as string,",
						"          saleItem as string,",
						"          country as string,",
						"          quantity as string",
						"     ),",
						"     partitionFileNames:[($fileName)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> logOutputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow2_Filter_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empdata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "FilteredOutputData"
						}
					],
					"transformations": [
						{
							"name": "filterEmpData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empdata",
						"empdata filter(equals(DeptID,'3')) ~> filterEmpData",
						"filterEmpData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> FilteredOutputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow3_Aggregate_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						},
						{
							"dataset": {
								"referenceName": "deptData",
								"type": "DatasetReference"
							},
							"name": "Deptdata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "OutputData"
						}
					],
					"transformations": [
						{
							"name": "aggregateDepartments"
						},
						{
							"name": "joinToGetDeptName"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"source(output(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Deptdata",
						"empData aggregate(groupBy(DeptID),",
						"     TotalCounnt = count(DeptID)) ~> aggregateDepartments",
						"aggregateDepartments, Deptdata join(aggregateDepartments@DeptID == Deptdata@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinToGetDeptName",
						"joinToGetDeptName sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          DeptName,",
						"          TotalCount = TotalCounnt",
						"     )) ~> OutputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow4_Conditional_Split')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputdata"
						},
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "softwareOutputData"
						},
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "DataEmployeeData"
						}
					],
					"transformations": [
						{
							"name": "splitFromDeparments"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"empData split(equals(DeptID, '1'),",
						"     equals(DeptID, '2'),",
						"     equals(DeptID, '3'),",
						"     disjoint: false) ~> splitFromDeparments@(HrEmployee, SoftwareEmployee, DataEmployee)",
						"splitFromDeparments@HrEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Hr.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputdata",
						"splitFromDeparments@SoftwareEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Software.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname,",
						"          Salary,",
						"          DeptID",
						"     ),",
						"     partitionBy('hash', 1)) ~> softwareOutputData",
						"splitFromDeparments@DataEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Data.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname,",
						"          Salary,",
						"          DeptID",
						"     ),",
						"     partitionBy('hash', 1)) ~> DataEmployeeData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5_Derived_column_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "EmpData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "derivedColumnFromEmpData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as short,",
						"          empname as string,",
						"          Country as string,",
						"          Salary as integer,",
						"          DeptID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> EmpData",
						"EmpData derive(Country = upper(Country),",
						"          NewCountry = iif(isNull(Country), 'Unknown', upper(Country))) ~> derivedColumnFromEmpData",
						"derivedColumnFromEmpData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['DerivedCountryData.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow6_exists_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						},
						{
							"dataset": {
								"referenceName": "deptData",
								"type": "DatasetReference"
							},
							"name": "deptData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "existsDepartemsData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"source(output(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> deptData",
						"empData, deptData exists(empData@DeptID == deptData@DeptID,",
						"     negate:false,",
						"     broadcast: 'auto')~> existsDepartemsData",
						"existsDepartemsData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['exists.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow7_union_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "HrData",
								"type": "DatasetReference"
							},
							"name": "HrData"
						},
						{
							"dataset": {
								"referenceName": "softwareData",
								"type": "DatasetReference"
							},
							"name": "SoftwareData"
						},
						{
							"dataset": {
								"referenceName": "Datadata",
								"type": "DatasetReference"
							},
							"name": "Datadata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "unionAllEmployeesData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> HrData",
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> SoftwareData",
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Datadata",
						"HrData, SoftwareData, Datadata union(byName: true)~> unionAllEmployeesData",
						"unionAllEmployeesData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['unionAllEmp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow8_lookup_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						},
						{
							"dataset": {
								"referenceName": "deptData",
								"type": "DatasetReference"
							},
							"name": "deptData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						}
					],
					"transformations": [
						{
							"name": "lookupMatchingEmpData"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"source(output(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> deptData",
						"empData, deptData lookup(empData@DeptID == deptData@DeptID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookupMatchingEmpData",
						"lookupMatchingEmpData sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['lookup.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow9_new_branch_operation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Practice"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "empData",
								"type": "DatasetReference"
							},
							"name": "empData"
						},
						{
							"dataset": {
								"referenceName": "deptData",
								"type": "DatasetReference"
							},
							"name": "DeptData"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputData"
						},
						{
							"dataset": {
								"referenceName": "Outputdata",
								"type": "DatasetReference"
							},
							"name": "outputDataNewbranch"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "aggregateOndeptForEmpCount"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          Salary as string,",
						"          DeptID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empData",
						"source(output(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DeptData",
						"empData, DeptData join(empData@DeptID == DeptData@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"empData aggregate(groupBy(DeptID),",
						"     totalEmpCount = count(empid)) ~> aggregateOndeptForEmpCount",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['newBranchJoinedData.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputData",
						"aggregateOndeptForEmpCount sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['newBranchAggregateData.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> outputDataNewbranch"
					]
				}
			},
			"dependsOn": []
		}
	]
}